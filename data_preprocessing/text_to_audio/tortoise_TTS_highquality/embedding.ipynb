{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mp3 -> wav -> embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\빅데이터9기_수업자료_이수지\\2024.11.04_(중간프로젝트)\\tortoise-tts\\tortoise\\api.py:221: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)\n",
      "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "c:\\Users\\user\\Desktop\\빅데이터9기_수업자료_이수지\\2024.11.04_(중간프로젝트)\\tortoise-tts\\tortoise\\api.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.diffusion.load_state_dict(torch.load(get_model_path('diffusion_decoder.pth', models_dir)))\n",
      "c:\\Users\\user\\Desktop\\빅데이터9기_수업자료_이수지\\2024.11.04_(중간프로젝트)\\tortoise-tts\\tortoise\\api.py:233: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.clvp.load_state_dict(torch.load(get_model_path('clvp2.pth', models_dir)))\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "c:\\Users\\user\\Desktop\\빅데이터9기_수업자료_이수지\\2024.11.04_(중간프로젝트)\\tortoise-tts\\tortoise\\api.py:237: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.vocoder.load_state_dict(torch.load(get_model_path('vocoder.pth', models_dir), map_location=torch.device('cpu'))['model_g'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'emilyclimbs_01_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_01_montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_02_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_02_montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_03_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_03_montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_04_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_04_montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_05_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_05_montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_06_Montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_06_Montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_07_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_07_montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_08_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_08_montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_09_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_09_montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_10_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_10_montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_11_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_11_montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_12_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_12_montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_13_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_13_montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_14_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_14_montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_15_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_15_montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_16_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_16_montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_17_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_17_montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_18_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_18_montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_19_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_19_montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_20_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_20_montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_21_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_21_montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_22_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_22_montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_23_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_23_montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_24_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_24_montgomery_64kb.wav'로 변환되었습니다.\n",
      "'emilyclimbs_25_montgomery_64kb.mp3'이 'emilyclimbs_wav_files\\emilyclimbs_25_montgomery_64kb.wav'로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_01_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_02_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_03_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_04_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_05_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_06_Montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_07_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_08_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_09_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_10_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_11_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_12_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_13_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_14_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_15_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_16_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_17_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_18_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_19_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_20_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_21_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_22_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_23_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_24_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n",
      "WAV 파일 'emilyclimbs_wav_files\\emilyclimbs_25_montgomery_64kb.wav'이 성공적으로 로드되어 텐서로 변환되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\빅데이터9기_수업자료_이수지\\2024.11.04_(중간프로젝트)\\tortoise-tts\\tortoise\\models\\arch_util.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.mel_norms = torch.load(self.mel_norm_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "화자 임베딩이 'saved_embeddings/conditioning_latents_emilyclimbs.npz'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tortoise.api import TextToSpeech\n",
    "from pydub import AudioSegment\n",
    "from scipy.io.wavfile import read as read_wav\n",
    "\n",
    "# Tortoise TTS 초기화\n",
    "tts = TextToSpeech(use_deepspeed=True, kv_cache=True, half=True)\n",
    "\n",
    "# MP3 파일이 들어있는 폴더 경로와 변환된 WAV 파일을 저장할 폴더 경로\n",
    "mp3_folder = \"emilyclimbs_2204_librivox\"  # MP3 파일 폴더 경로\n",
    "wav_folder = \"emilyclimbs_wav_files\"  # WAV 파일이 저장될 폴더 경로\n",
    "os.makedirs(wav_folder, exist_ok=True)\n",
    "\n",
    "# 변환된 WAV 파일을 저장할 리스트\n",
    "wav_files = []\n",
    "\n",
    "# MP3 파일을 WAV로 변환\n",
    "for mp3_file in os.listdir(mp3_folder):\n",
    "    if mp3_file.endswith(\".mp3\"):\n",
    "        mp3_path = os.path.join(mp3_folder, mp3_file)\n",
    "        \n",
    "        # MP3를 로드하여 WAV로 변환\n",
    "        audio = AudioSegment.from_mp3(mp3_path)\n",
    "        audio = audio.set_frame_rate(22050).set_channels(1)  # 샘플링 레이트와 채널 설정\n",
    "        wav_path = os.path.join(wav_folder, mp3_file.replace(\".mp3\", \".wav\"))\n",
    "        audio.export(wav_path, format=\"wav\")\n",
    "        wav_files.append(wav_path)\n",
    "        print(f\"'{mp3_file}'이 '{wav_path}'로 변환되었습니다.\")\n",
    "\n",
    "# 변환된 WAV 파일들을 로드하여 임베딩 생성\n",
    "voice_samples = []\n",
    "for wav_file in wav_files:\n",
    "    try:\n",
    "        # WAV 파일을 읽고 정규화하여 텐서로 변환\n",
    "        sr, wav_audio = read_wav(wav_file)\n",
    "        \n",
    "        # 스테레오인 경우 모노로 변환\n",
    "        if wav_audio.ndim > 1:\n",
    "            wav_audio = wav_audio.mean(axis=1)\n",
    "        \n",
    "        # 정규화: -1 ~ 1 범위로 스케일 조정\n",
    "        wav_audio = wav_audio / np.max(np.abs(wav_audio))  # 오디오 데이터를 -1에서 1 사이로 스케일 조정\n",
    "        \n",
    "        # torch.Tensor로 변환하고 차원 추가\n",
    "        audio_tensor = torch.tensor(wav_audio, dtype=torch.float32).unsqueeze(0)  # (1, 샘플 길이)\n",
    "        voice_samples.append(audio_tensor)\n",
    "        print(f\"WAV 파일 '{wav_file}'이 성공적으로 로드되어 텐서로 변환되었습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"{wav_file} 로드 중 오류 발생: {e}\")\n",
    "\n",
    "# 임베딩 생성\n",
    "conditioning_latents = tts.get_conditioning_latents(voice_samples)\n",
    "\n",
    "# 임베딩을 저장할 경로\n",
    "embedding_path = \"saved_embeddings/conditioning_latents_emilyclimbs.npz\"\n",
    "os.makedirs(os.path.dirname(embedding_path), exist_ok=True)\n",
    "np.savez(embedding_path, *conditioning_latents)\n",
    "print(f\"화자 임베딩이 '{embedding_path}'에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### m4b -> wav 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0.2-full_build-www.gyan.dev Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with gcc 13.2.0 (Rev5, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-sdl2 --enable-libaribb24 --enable-libaribcaption --enable-libdav1d --enable-libdavs2 --enable-libuavs3d --enable-libxevd --enable-libzvbi --enable-librav1e --enable-libsvtav1 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxeve --enable-libxvid --enable-libaom --enable-libjxl --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libcodec2 --enable-libilbc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 000001e55d0370c0] Skipping unhandled metadata genre of type 18\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 000001e55d0370c0] Unknown cover type: 0x0.\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'GalacticPatrol2_librivox.m4b':\n",
      "  Metadata:\n",
      "    major_brand     : M4A\n",
      "    minor_version   : 0\n",
      "    compatible_brands: 3gp5isom\n",
      "    creation_time   : 2024-10-01T10:59:56.000000Z\n",
      "    media_type      : 2\n",
      "    encoder         : Chapter and Verse V 1.5\n",
      "    title           : GalacticPatrol2_librivox\n",
      "    artist          : E. E. Smith\n",
      "    album           : Galactic Patrol (version 2)\n",
      "    comment         : https://archive.org/details/galacticpatrolversion2_2409_librivox\n",
      "    track           : 1\n",
      "    Encoding Params : vers\n",
      "  Duration: 08:39:15.88, start: 0.000000, bitrate: 64 kb/s\n",
      "  Chapters:\n",
      "    Chapter #0:0: start 0.000000, end 1379.009184\n",
      "      Metadata:\n",
      "        title           : 01 - I\n",
      "    Chapter #0:1: start 1379.009184, end 2691.021224\n",
      "      Metadata:\n",
      "        title           : 02 - II\n",
      "    Chapter #0:2: start 2691.021224, end 4109.011134\n",
      "      Metadata:\n",
      "        title           : 03 - III\n",
      "    Chapter #0:3: start 4109.011134, end 4767.010227\n",
      "      Metadata:\n",
      "        title           : 04 - IV\n",
      "    Chapter #0:4: start 4767.010227, end 6693.007120\n",
      "      Metadata:\n",
      "        title           : 05 - V\n",
      "    Chapter #0:5: start 6693.007120, end 7998.020998\n",
      "      Metadata:\n",
      "        title           : 06 - VI\n",
      "    Chapter #0:6: start 7998.020998, end 9366.012132\n",
      "      Metadata:\n",
      "        title           : 07 - VII\n",
      "    Chapter #0:7: start 9366.012132, end 10718.015941\n",
      "      Metadata:\n",
      "        title           : 08 - VIII\n",
      "    Chapter #0:8: start 10718.015941, end 11927.002086\n",
      "      Metadata:\n",
      "        title           : 09 - IX\n",
      "    Chapter #0:9: start 11927.002086, end 13429.020658\n",
      "      Metadata:\n",
      "        title           : 10 - X\n",
      "    Chapter #0:10: start 13429.020658, end 14698.001565\n",
      "      Metadata:\n",
      "        title           : 11 - XI\n",
      "    Chapter #0:11: start 14698.001565, end 16059.013469\n",
      "      Metadata:\n",
      "        title           : 12 - XII\n",
      "    Chapter #0:12: start 16059.013469, end 17175.016576\n",
      "      Metadata:\n",
      "        title           : 13 - XIII\n",
      "    Chapter #0:13: start 17175.016576, end 18573.000862\n",
      "      Metadata:\n",
      "        title           : 14 - XIV\n",
      "    Chapter #0:14: start 18573.000862, end 19742.005261\n",
      "      Metadata:\n",
      "        title           : 15 - XV\n",
      "    Chapter #0:15: start 19742.005261, end 21193.018254\n",
      "      Metadata:\n",
      "        title           : 16 - XVI\n",
      "    Chapter #0:16: start 21193.018254, end 22430.005011\n",
      "      Metadata:\n",
      "        title           : 17 - XVII\n",
      "    Chapter #0:17: start 22430.005011, end 23950.010839\n",
      "      Metadata:\n",
      "        title           : 18 - XVIII\n",
      "    Chapter #0:18: start 23950.010839, end 25136.022540\n",
      "      Metadata:\n",
      "        title           : 19 - XIX\n",
      "    Chapter #0:19: start 25136.022540, end 26355.002041\n",
      "      Metadata:\n",
      "        title           : 20 - XX\n",
      "    Chapter #0:20: start 26355.002041, end 27605.000454\n",
      "      Metadata:\n",
      "        title           : 21 - XXI\n",
      "    Chapter #0:21: start 27605.000454, end 29025.009252\n",
      "      Metadata:\n",
      "        title           : 22 - XXII\n",
      "    Chapter #0:22: start 29025.009252, end 30064.015556\n",
      "      Metadata:\n",
      "        title           : 23 - XXIII\n",
      "    Chapter #0:23: start 30064.015556, end 31155.884989\n",
      "      Metadata:\n",
      "        title           : 24 - XXIV\n",
      "  Stream #0:0[0x1](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, mono, fltp, 62 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-10-01T10:59:56.000000Z\n",
      "        vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1[0x2](und): Data: bin_data (text / 0x74786574)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-10-01T11:00:28.000000Z\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (aac (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'GalacticPatrol2.wav':\n",
      "  Metadata:\n",
      "    major_brand     : M4A\n",
      "    minor_version   : 0\n",
      "    compatible_brands: 3gp5isom\n",
      "    Encoding Params : vers\n",
      "    media_type      : 2\n",
      "    IPRT            : 1\n",
      "    INAM            : GalacticPatrol2_librivox\n",
      "    IART            : E. E. Smith\n",
      "    IPRD            : Galactic Patrol (version 2)\n",
      "    ICMT            : https://archive.org/details/galacticpatrolversion2_2409_librivox\n",
      "    ISFT            : Lavf61.1.100\n",
      "  Chapters:\n",
      "    Chapter #0:0: start 0.000000, end 1379.009184\n",
      "      Metadata:\n",
      "        title           : 01 - I\n",
      "    Chapter #0:1: start 1379.009184, end 2691.021224\n",
      "      Metadata:\n",
      "        title           : 02 - II\n",
      "    Chapter #0:2: start 2691.021224, end 4109.011134\n",
      "      Metadata:\n",
      "        title           : 03 - III\n",
      "    Chapter #0:3: start 4109.011134, end 4767.010227\n",
      "      Metadata:\n",
      "        title           : 04 - IV\n",
      "    Chapter #0:4: start 4767.010227, end 6693.007120\n",
      "      Metadata:\n",
      "        title           : 05 - V\n",
      "    Chapter #0:5: start 6693.007120, end 7998.020998\n",
      "      Metadata:\n",
      "        title           : 06 - VI\n",
      "    Chapter #0:6: start 7998.020998, end 9366.012132\n",
      "      Metadata:\n",
      "        title           : 07 - VII\n",
      "    Chapter #0:7: start 9366.012132, end 10718.015941\n",
      "      Metadata:\n",
      "        title           : 08 - VIII\n",
      "    Chapter #0:8: start 10718.015941, end 11927.002086\n",
      "      Metadata:\n",
      "        title           : 09 - IX\n",
      "    Chapter #0:9: start 11927.002086, end 13429.020658\n",
      "      Metadata:\n",
      "        title           : 10 - X\n",
      "    Chapter #0:10: start 13429.020658, end 14698.001565\n",
      "      Metadata:\n",
      "        title           : 11 - XI\n",
      "    Chapter #0:11: start 14698.001565, end 16059.013469\n",
      "      Metadata:\n",
      "        title           : 12 - XII\n",
      "    Chapter #0:12: start 16059.013469, end 17175.016576\n",
      "      Metadata:\n",
      "        title           : 13 - XIII\n",
      "    Chapter #0:13: start 17175.016576, end 18573.000862\n",
      "      Metadata:\n",
      "        title           : 14 - XIV\n",
      "    Chapter #0:14: start 18573.000862, end 19742.005261\n",
      "      Metadata:\n",
      "        title           : 15 - XV\n",
      "    Chapter #0:15: start 19742.005261, end 21193.018254\n",
      "      Metadata:\n",
      "        title           : 16 - XVI\n",
      "    Chapter #0:16: start 21193.018254, end 22430.005011\n",
      "      Metadata:\n",
      "        title           : 17 - XVII\n",
      "    Chapter #0:17: start 22430.005011, end 23950.010839\n",
      "      Metadata:\n",
      "        title           : 18 - XVIII\n",
      "    Chapter #0:18: start 23950.010839, end 25136.022540\n",
      "      Metadata:\n",
      "        title           : 19 - XIX\n",
      "    Chapter #0:19: start 25136.022540, end 26355.002041\n",
      "      Metadata:\n",
      "        title           : 20 - XX\n",
      "    Chapter #0:20: start 26355.002041, end 27605.000454\n",
      "      Metadata:\n",
      "        title           : 21 - XXI\n",
      "    Chapter #0:21: start 27605.000454, end 29025.009252\n",
      "      Metadata:\n",
      "        title           : 22 - XXII\n",
      "    Chapter #0:22: start 29025.009252, end 30064.015556\n",
      "      Metadata:\n",
      "        title           : 23 - XXIII\n",
      "    Chapter #0:23: start 30064.015556, end 31155.884989\n",
      "      Metadata:\n",
      "        title           : 24 - XXIV\n",
      "  Stream #0:0(und): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22050 Hz, mono, s16, 352 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-10-01T10:59:56.000000Z\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.3.100 pcm_s16le\n",
      "size=   74496KiB time=00:28:52.20 bitrate= 352.3kbits/s speed=3.33e+03x    \n",
      "size=  146432KiB time=00:56:46.27 bitrate= 352.2kbits/s speed=3.29e+03x    \n",
      "size=  219648KiB time=01:25:02.51 bitrate= 352.6kbits/s speed=3.28e+03x    \n",
      "size=  293888KiB time=01:53:44.39 bitrate= 352.8kbits/s speed=3.32e+03x    \n",
      "size=  368384KiB time=02:22:37.94 bitrate= 352.6kbits/s speed=3.31e+03x    \n",
      "size=  443136KiB time=02:51:35.61 bitrate= 352.6kbits/s speed=3.32e+03x    \n",
      "size=  513280KiB time=03:18:40.98 bitrate= 352.7kbits/s speed=3.3e+03x    \n",
      "size=  587776KiB time=03:47:32.10 bitrate= 352.7kbits/s speed=3.3e+03x    \n",
      "size=  662784KiB time=04:16:32.85 bitrate= 352.7kbits/s speed=3.31e+03x    \n",
      "size=  738816KiB time=04:45:55.94 bitrate= 352.8kbits/s speed=3.32e+03x    \n",
      "size=  810496KiB time=05:13:42.95 bitrate= 352.7kbits/s speed=3.31e+03x    \n",
      "size=  885760KiB time=05:42:49.46 bitrate= 352.8kbits/s speed=3.32e+03x    \n",
      "size=  955648KiB time=06:09:54.58 bitrate= 352.7kbits/s speed=3.31e+03x    \n",
      "size= 1026048KiB time=06:37:09.19 bitrate= 352.7kbits/s speed=3.3e+03x    \n",
      "size= 1103616KiB time=07:07:10.69 bitrate= 352.7kbits/s speed=3.31e+03x    \n",
      "size= 1177344KiB time=07:35:42.95 bitrate= 352.7kbits/s speed=3.31e+03x    \n",
      "size= 1249536KiB time=08:03:36.83 bitrate= 352.8kbits/s speed=3.3e+03x    \n",
      "size= 1320448KiB time=08:31:06.87 bitrate= 352.7kbits/s speed=3.3e+03x    \n",
      "[out#0/wav @ 000001e55d03ba80] video:0KiB audio:1341772KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.000018%\n",
      "size= 1341772KiB time=08:39:15.88 bitrate= 352.8kbits/s speed=3.27e+03x    \n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -i GalacticPatrol2_librivox.m4b -ac 1 -ar 22050 GalacticPatrol2.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임베딩 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tortoise.api import TextToSpeech\n",
    "from scipy.io.wavfile import read as read_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\빅데이터9기_수업자료_이수지\\2024.11.04_(중간프로젝트)\\tortoise-tts\\tortoise\\api.py:221: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)\n",
      "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "c:\\Users\\user\\Desktop\\빅데이터9기_수업자료_이수지\\2024.11.04_(중간프로젝트)\\tortoise-tts\\tortoise\\api.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.diffusion.load_state_dict(torch.load(get_model_path('diffusion_decoder.pth', models_dir)))\n",
      "c:\\Users\\user\\Desktop\\빅데이터9기_수업자료_이수지\\2024.11.04_(중간프로젝트)\\tortoise-tts\\tortoise\\api.py:233: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.clvp.load_state_dict(torch.load(get_model_path('clvp2.pth', models_dir)))\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "c:\\Users\\user\\Desktop\\빅데이터9기_수업자료_이수지\\2024.11.04_(중간프로젝트)\\tortoise-tts\\tortoise\\api.py:237: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.vocoder.load_state_dict(torch.load(get_model_path('vocoder.pth', models_dir), map_location=torch.device('cpu'))['model_g'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAV 파일이 성공적으로 로드되어 텐서로 변환되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# Tortoise TTS 모델 초기화\n",
    "tts = TextToSpeech(use_deepspeed=True, kv_cache=True, half=True)\n",
    "\n",
    "wav_path = \"GalacticPatrol2.wav\"  # 변환된 WAV 파일 경로\n",
    "\n",
    "# WAV 파일을 로드하고 텐서로 변환\n",
    "try:\n",
    "    sr, wav_audio = read_wav(wav_path)\n",
    "    \n",
    "    # 스테레오인 경우 모노로 변환\n",
    "    if wav_audio.ndim > 1:\n",
    "        wav_audio = wav_audio.mean(axis=1)\n",
    "\n",
    "    # 정규화: -1 ~ 1 범위로 스케일 조정\n",
    "    wav_audio = wav_audio / np.max(np.abs(wav_audio))  # 오디오 데이터를 -1에서 1 사이로 스케일 조정\n",
    "\n",
    "    # torch.Tensor로 변환하고 차원 추가\n",
    "    audio_tensor = torch.tensor(wav_audio, dtype=torch.float32).unsqueeze(0)\n",
    "    print(f\"WAV 파일이 성공적으로 로드되어 텐서로 변환되었습니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"WAV 파일을 로드하는 중 오류 발생: {e}\")\n",
    "    raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\빅데이터9기_수업자료_이수지\\2024.11.04_(중간프로젝트)\\tortoise-tts\\tortoise\\models\\arch_util.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.mel_norms = torch.load(self.mel_norm_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "화자 임베딩이 'saved_embeddings/conditioning_latents_GalacticPatrol2'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# Tortoise TTS에서 화자 프로필 임베딩 생성\n",
    "conditioning_latents = tts.get_conditioning_latents([audio_tensor])\n",
    "\n",
    "# 임베딩 저장\n",
    "embedding_path = \"saved_embeddings/conditioning_latents_GalacticPatrol2\"\n",
    "os.makedirs(os.path.dirname(embedding_path), exist_ok=True)\n",
    "np.savez(embedding_path, *conditioning_latents)\n",
    "print(f\"화자 임베딩이 '{embedding_path}'에 저장되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
