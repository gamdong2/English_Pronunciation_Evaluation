{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mp3 -> wav -> embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:221: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)\n",
      "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ğŸ‘‰v4.50ğŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.diffusion.load_state_dict(torch.load(get_model_path('diffusion_decoder.pth', models_dir)))\n",
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:233: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.clvp.load_state_dict(torch.load(get_model_path('clvp2.pth', models_dir)))\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:237: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.vocoder.load_state_dict(torch.load(get_model_path('vocoder.pth', models_dir), map_location=torch.device('cpu'))['model_g'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'emilyclimbs_01_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_01_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_02_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_02_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_03_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_03_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_04_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_04_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_05_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_05_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_06_Montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_06_Montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_07_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_07_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_08_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_08_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_09_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_09_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_10_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_10_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_11_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_11_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_12_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_12_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_13_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_13_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_14_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_14_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_15_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_15_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_16_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_16_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_17_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_17_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_18_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_18_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_19_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_19_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_20_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_20_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_21_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_21_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_22_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_22_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_23_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_23_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_24_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_24_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "'emilyclimbs_25_montgomery_64kb.mp3'ì´ 'emilyclimbs_wav_files\\emilyclimbs_25_montgomery_64kb.wav'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_01_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_02_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_03_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_04_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_05_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_06_Montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_07_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_08_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_09_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_10_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_11_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_12_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_13_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_14_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_15_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_16_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_17_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_18_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_19_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_20_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_21_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_22_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_23_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_24_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "WAV íŒŒì¼ 'emilyclimbs_wav_files\\emilyclimbs_25_montgomery_64kb.wav'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\models\\arch_util.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.mel_norms = torch.load(self.mel_norm_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í™”ì ì„ë² ë”©ì´ 'saved_embeddings/conditioning_latents_emilyclimbs.npz'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tortoise.api import TextToSpeech\n",
    "from pydub import AudioSegment\n",
    "from scipy.io.wavfile import read as read_wav\n",
    "\n",
    "# Tortoise TTS ì´ˆê¸°í™”\n",
    "tts = TextToSpeech(use_deepspeed=True, kv_cache=True, half=True)\n",
    "\n",
    "# MP3 íŒŒì¼ì´ ë“¤ì–´ìˆëŠ” í´ë” ê²½ë¡œì™€ ë³€í™˜ëœ WAV íŒŒì¼ì„ ì €ì¥í•  í´ë” ê²½ë¡œ\n",
    "mp3_folder = \"emilyclimbs_2204_librivox\"  # MP3 íŒŒì¼ í´ë” ê²½ë¡œ\n",
    "wav_folder = \"emilyclimbs_wav_files\"  # WAV íŒŒì¼ì´ ì €ì¥ë  í´ë” ê²½ë¡œ\n",
    "os.makedirs(wav_folder, exist_ok=True)\n",
    "\n",
    "# ë³€í™˜ëœ WAV íŒŒì¼ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "wav_files = []\n",
    "\n",
    "# MP3 íŒŒì¼ì„ WAVë¡œ ë³€í™˜\n",
    "for mp3_file in os.listdir(mp3_folder):\n",
    "    if mp3_file.endswith(\".mp3\"):\n",
    "        mp3_path = os.path.join(mp3_folder, mp3_file)\n",
    "        \n",
    "        # MP3ë¥¼ ë¡œë“œí•˜ì—¬ WAVë¡œ ë³€í™˜\n",
    "        audio = AudioSegment.from_mp3(mp3_path)\n",
    "        audio = audio.set_frame_rate(22050).set_channels(1)  # ìƒ˜í”Œë§ ë ˆì´íŠ¸ì™€ ì±„ë„ ì„¤ì •\n",
    "        wav_path = os.path.join(wav_folder, mp3_file.replace(\".mp3\", \".wav\"))\n",
    "        audio.export(wav_path, format=\"wav\")\n",
    "        wav_files.append(wav_path)\n",
    "        print(f\"'{mp3_file}'ì´ '{wav_path}'ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ë³€í™˜ëœ WAV íŒŒì¼ë“¤ì„ ë¡œë“œí•˜ì—¬ ì„ë² ë”© ìƒì„±\n",
    "voice_samples = []\n",
    "for wav_file in wav_files:\n",
    "    try:\n",
    "        # WAV íŒŒì¼ì„ ì½ê³  ì •ê·œí™”í•˜ì—¬ í…ì„œë¡œ ë³€í™˜\n",
    "        sr, wav_audio = read_wav(wav_file)\n",
    "        \n",
    "        # ìŠ¤í…Œë ˆì˜¤ì¸ ê²½ìš° ëª¨ë…¸ë¡œ ë³€í™˜\n",
    "        if wav_audio.ndim > 1:\n",
    "            wav_audio = wav_audio.mean(axis=1)\n",
    "        \n",
    "        # ì •ê·œí™”: -1 ~ 1 ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ ì¡°ì •\n",
    "        wav_audio = wav_audio / np.max(np.abs(wav_audio))  # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ -1ì—ì„œ 1 ì‚¬ì´ë¡œ ìŠ¤ì¼€ì¼ ì¡°ì •\n",
    "        \n",
    "        # torch.Tensorë¡œ ë³€í™˜í•˜ê³  ì°¨ì› ì¶”ê°€\n",
    "        audio_tensor = torch.tensor(wav_audio, dtype=torch.float32).unsqueeze(0)  # (1, ìƒ˜í”Œ ê¸¸ì´)\n",
    "        voice_samples.append(audio_tensor)\n",
    "        print(f\"WAV íŒŒì¼ '{wav_file}'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    except Exception as e:\n",
    "        print(f\"{wav_file} ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "# ì„ë² ë”© ìƒì„±\n",
    "conditioning_latents = tts.get_conditioning_latents(voice_samples)\n",
    "\n",
    "# ì„ë² ë”©ì„ ì €ì¥í•  ê²½ë¡œ\n",
    "embedding_path = \"saved_embeddings/conditioning_latents_emilyclimbs.npz\"\n",
    "os.makedirs(os.path.dirname(embedding_path), exist_ok=True)\n",
    "np.savez(embedding_path, *conditioning_latents)\n",
    "print(f\"í™”ì ì„ë² ë”©ì´ '{embedding_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### m4b -> wav ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0.2-full_build-www.gyan.dev Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with gcc 13.2.0 (Rev5, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-sdl2 --enable-libaribb24 --enable-libaribcaption --enable-libdav1d --enable-libdavs2 --enable-libuavs3d --enable-libxevd --enable-libzvbi --enable-librav1e --enable-libsvtav1 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxeve --enable-libxvid --enable-libaom --enable-libjxl --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libcodec2 --enable-libilbc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 000001e55d0370c0] Skipping unhandled metadata genre of type 18\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 000001e55d0370c0] Unknown cover type: 0x0.\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'GalacticPatrol2_librivox.m4b':\n",
      "  Metadata:\n",
      "    major_brand     : M4A\n",
      "    minor_version   : 0\n",
      "    compatible_brands: 3gp5isom\n",
      "    creation_time   : 2024-10-01T10:59:56.000000Z\n",
      "    media_type      : 2\n",
      "    encoder         : Chapter and Verse V 1.5\n",
      "    title           : GalacticPatrol2_librivox\n",
      "    artist          : E. E. Smith\n",
      "    album           : Galactic Patrol (version 2)\n",
      "    comment         : https://archive.org/details/galacticpatrolversion2_2409_librivox\n",
      "    track           : 1\n",
      "    Encoding Params : vers\n",
      "  Duration: 08:39:15.88, start: 0.000000, bitrate: 64 kb/s\n",
      "  Chapters:\n",
      "    Chapter #0:0: start 0.000000, end 1379.009184\n",
      "      Metadata:\n",
      "        title           : 01 - I\n",
      "    Chapter #0:1: start 1379.009184, end 2691.021224\n",
      "      Metadata:\n",
      "        title           : 02 - II\n",
      "    Chapter #0:2: start 2691.021224, end 4109.011134\n",
      "      Metadata:\n",
      "        title           : 03 - III\n",
      "    Chapter #0:3: start 4109.011134, end 4767.010227\n",
      "      Metadata:\n",
      "        title           : 04 - IV\n",
      "    Chapter #0:4: start 4767.010227, end 6693.007120\n",
      "      Metadata:\n",
      "        title           : 05 - V\n",
      "    Chapter #0:5: start 6693.007120, end 7998.020998\n",
      "      Metadata:\n",
      "        title           : 06 - VI\n",
      "    Chapter #0:6: start 7998.020998, end 9366.012132\n",
      "      Metadata:\n",
      "        title           : 07 - VII\n",
      "    Chapter #0:7: start 9366.012132, end 10718.015941\n",
      "      Metadata:\n",
      "        title           : 08 - VIII\n",
      "    Chapter #0:8: start 10718.015941, end 11927.002086\n",
      "      Metadata:\n",
      "        title           : 09 - IX\n",
      "    Chapter #0:9: start 11927.002086, end 13429.020658\n",
      "      Metadata:\n",
      "        title           : 10 - X\n",
      "    Chapter #0:10: start 13429.020658, end 14698.001565\n",
      "      Metadata:\n",
      "        title           : 11 - XI\n",
      "    Chapter #0:11: start 14698.001565, end 16059.013469\n",
      "      Metadata:\n",
      "        title           : 12 - XII\n",
      "    Chapter #0:12: start 16059.013469, end 17175.016576\n",
      "      Metadata:\n",
      "        title           : 13 - XIII\n",
      "    Chapter #0:13: start 17175.016576, end 18573.000862\n",
      "      Metadata:\n",
      "        title           : 14 - XIV\n",
      "    Chapter #0:14: start 18573.000862, end 19742.005261\n",
      "      Metadata:\n",
      "        title           : 15 - XV\n",
      "    Chapter #0:15: start 19742.005261, end 21193.018254\n",
      "      Metadata:\n",
      "        title           : 16 - XVI\n",
      "    Chapter #0:16: start 21193.018254, end 22430.005011\n",
      "      Metadata:\n",
      "        title           : 17 - XVII\n",
      "    Chapter #0:17: start 22430.005011, end 23950.010839\n",
      "      Metadata:\n",
      "        title           : 18 - XVIII\n",
      "    Chapter #0:18: start 23950.010839, end 25136.022540\n",
      "      Metadata:\n",
      "        title           : 19 - XIX\n",
      "    Chapter #0:19: start 25136.022540, end 26355.002041\n",
      "      Metadata:\n",
      "        title           : 20 - XX\n",
      "    Chapter #0:20: start 26355.002041, end 27605.000454\n",
      "      Metadata:\n",
      "        title           : 21 - XXI\n",
      "    Chapter #0:21: start 27605.000454, end 29025.009252\n",
      "      Metadata:\n",
      "        title           : 22 - XXII\n",
      "    Chapter #0:22: start 29025.009252, end 30064.015556\n",
      "      Metadata:\n",
      "        title           : 23 - XXIII\n",
      "    Chapter #0:23: start 30064.015556, end 31155.884989\n",
      "      Metadata:\n",
      "        title           : 24 - XXIV\n",
      "  Stream #0:0[0x1](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, mono, fltp, 62 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-10-01T10:59:56.000000Z\n",
      "        vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1[0x2](und): Data: bin_data (text / 0x74786574)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-10-01T11:00:28.000000Z\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (aac (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'GalacticPatrol2.wav':\n",
      "  Metadata:\n",
      "    major_brand     : M4A\n",
      "    minor_version   : 0\n",
      "    compatible_brands: 3gp5isom\n",
      "    Encoding Params : vers\n",
      "    media_type      : 2\n",
      "    IPRT            : 1\n",
      "    INAM            : GalacticPatrol2_librivox\n",
      "    IART            : E. E. Smith\n",
      "    IPRD            : Galactic Patrol (version 2)\n",
      "    ICMT            : https://archive.org/details/galacticpatrolversion2_2409_librivox\n",
      "    ISFT            : Lavf61.1.100\n",
      "  Chapters:\n",
      "    Chapter #0:0: start 0.000000, end 1379.009184\n",
      "      Metadata:\n",
      "        title           : 01 - I\n",
      "    Chapter #0:1: start 1379.009184, end 2691.021224\n",
      "      Metadata:\n",
      "        title           : 02 - II\n",
      "    Chapter #0:2: start 2691.021224, end 4109.011134\n",
      "      Metadata:\n",
      "        title           : 03 - III\n",
      "    Chapter #0:3: start 4109.011134, end 4767.010227\n",
      "      Metadata:\n",
      "        title           : 04 - IV\n",
      "    Chapter #0:4: start 4767.010227, end 6693.007120\n",
      "      Metadata:\n",
      "        title           : 05 - V\n",
      "    Chapter #0:5: start 6693.007120, end 7998.020998\n",
      "      Metadata:\n",
      "        title           : 06 - VI\n",
      "    Chapter #0:6: start 7998.020998, end 9366.012132\n",
      "      Metadata:\n",
      "        title           : 07 - VII\n",
      "    Chapter #0:7: start 9366.012132, end 10718.015941\n",
      "      Metadata:\n",
      "        title           : 08 - VIII\n",
      "    Chapter #0:8: start 10718.015941, end 11927.002086\n",
      "      Metadata:\n",
      "        title           : 09 - IX\n",
      "    Chapter #0:9: start 11927.002086, end 13429.020658\n",
      "      Metadata:\n",
      "        title           : 10 - X\n",
      "    Chapter #0:10: start 13429.020658, end 14698.001565\n",
      "      Metadata:\n",
      "        title           : 11 - XI\n",
      "    Chapter #0:11: start 14698.001565, end 16059.013469\n",
      "      Metadata:\n",
      "        title           : 12 - XII\n",
      "    Chapter #0:12: start 16059.013469, end 17175.016576\n",
      "      Metadata:\n",
      "        title           : 13 - XIII\n",
      "    Chapter #0:13: start 17175.016576, end 18573.000862\n",
      "      Metadata:\n",
      "        title           : 14 - XIV\n",
      "    Chapter #0:14: start 18573.000862, end 19742.005261\n",
      "      Metadata:\n",
      "        title           : 15 - XV\n",
      "    Chapter #0:15: start 19742.005261, end 21193.018254\n",
      "      Metadata:\n",
      "        title           : 16 - XVI\n",
      "    Chapter #0:16: start 21193.018254, end 22430.005011\n",
      "      Metadata:\n",
      "        title           : 17 - XVII\n",
      "    Chapter #0:17: start 22430.005011, end 23950.010839\n",
      "      Metadata:\n",
      "        title           : 18 - XVIII\n",
      "    Chapter #0:18: start 23950.010839, end 25136.022540\n",
      "      Metadata:\n",
      "        title           : 19 - XIX\n",
      "    Chapter #0:19: start 25136.022540, end 26355.002041\n",
      "      Metadata:\n",
      "        title           : 20 - XX\n",
      "    Chapter #0:20: start 26355.002041, end 27605.000454\n",
      "      Metadata:\n",
      "        title           : 21 - XXI\n",
      "    Chapter #0:21: start 27605.000454, end 29025.009252\n",
      "      Metadata:\n",
      "        title           : 22 - XXII\n",
      "    Chapter #0:22: start 29025.009252, end 30064.015556\n",
      "      Metadata:\n",
      "        title           : 23 - XXIII\n",
      "    Chapter #0:23: start 30064.015556, end 31155.884989\n",
      "      Metadata:\n",
      "        title           : 24 - XXIV\n",
      "  Stream #0:0(und): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22050 Hz, mono, s16, 352 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-10-01T10:59:56.000000Z\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.3.100 pcm_s16le\n",
      "size=   74496KiB time=00:28:52.20 bitrate= 352.3kbits/s speed=3.33e+03x    \n",
      "size=  146432KiB time=00:56:46.27 bitrate= 352.2kbits/s speed=3.29e+03x    \n",
      "size=  219648KiB time=01:25:02.51 bitrate= 352.6kbits/s speed=3.28e+03x    \n",
      "size=  293888KiB time=01:53:44.39 bitrate= 352.8kbits/s speed=3.32e+03x    \n",
      "size=  368384KiB time=02:22:37.94 bitrate= 352.6kbits/s speed=3.31e+03x    \n",
      "size=  443136KiB time=02:51:35.61 bitrate= 352.6kbits/s speed=3.32e+03x    \n",
      "size=  513280KiB time=03:18:40.98 bitrate= 352.7kbits/s speed=3.3e+03x    \n",
      "size=  587776KiB time=03:47:32.10 bitrate= 352.7kbits/s speed=3.3e+03x    \n",
      "size=  662784KiB time=04:16:32.85 bitrate= 352.7kbits/s speed=3.31e+03x    \n",
      "size=  738816KiB time=04:45:55.94 bitrate= 352.8kbits/s speed=3.32e+03x    \n",
      "size=  810496KiB time=05:13:42.95 bitrate= 352.7kbits/s speed=3.31e+03x    \n",
      "size=  885760KiB time=05:42:49.46 bitrate= 352.8kbits/s speed=3.32e+03x    \n",
      "size=  955648KiB time=06:09:54.58 bitrate= 352.7kbits/s speed=3.31e+03x    \n",
      "size= 1026048KiB time=06:37:09.19 bitrate= 352.7kbits/s speed=3.3e+03x    \n",
      "size= 1103616KiB time=07:07:10.69 bitrate= 352.7kbits/s speed=3.31e+03x    \n",
      "size= 1177344KiB time=07:35:42.95 bitrate= 352.7kbits/s speed=3.31e+03x    \n",
      "size= 1249536KiB time=08:03:36.83 bitrate= 352.8kbits/s speed=3.3e+03x    \n",
      "size= 1320448KiB time=08:31:06.87 bitrate= 352.7kbits/s speed=3.3e+03x    \n",
      "[out#0/wav @ 000001e55d03ba80] video:0KiB audio:1341772KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.000018%\n",
      "size= 1341772KiB time=08:39:15.88 bitrate= 352.8kbits/s speed=3.27e+03x    \n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -i GalacticPatrol2_librivox.m4b -ac 1 -ar 22050 GalacticPatrol2.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì„ë² ë”© ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tortoise.api import TextToSpeech\n",
    "from scipy.io.wavfile import read as read_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:221: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)\n",
      "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ğŸ‘‰v4.50ğŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.diffusion.load_state_dict(torch.load(get_model_path('diffusion_decoder.pth', models_dir)))\n",
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:233: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.clvp.load_state_dict(torch.load(get_model_path('clvp2.pth', models_dir)))\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\api.py:237: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.vocoder.load_state_dict(torch.load(get_model_path('vocoder.pth', models_dir), map_location=torch.device('cpu'))['model_g'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAV íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# Tortoise TTS ëª¨ë¸ ì´ˆê¸°í™”\n",
    "tts = TextToSpeech(use_deepspeed=True, kv_cache=True, half=True)\n",
    "\n",
    "wav_path = \"GalacticPatrol2.wav\"  # ë³€í™˜ëœ WAV íŒŒì¼ ê²½ë¡œ\n",
    "\n",
    "# WAV íŒŒì¼ì„ ë¡œë“œí•˜ê³  í…ì„œë¡œ ë³€í™˜\n",
    "try:\n",
    "    sr, wav_audio = read_wav(wav_path)\n",
    "    \n",
    "    # ìŠ¤í…Œë ˆì˜¤ì¸ ê²½ìš° ëª¨ë…¸ë¡œ ë³€í™˜\n",
    "    if wav_audio.ndim > 1:\n",
    "        wav_audio = wav_audio.mean(axis=1)\n",
    "\n",
    "    # ì •ê·œí™”: -1 ~ 1 ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ ì¡°ì •\n",
    "    wav_audio = wav_audio / np.max(np.abs(wav_audio))  # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ -1ì—ì„œ 1 ì‚¬ì´ë¡œ ìŠ¤ì¼€ì¼ ì¡°ì •\n",
    "\n",
    "    # torch.Tensorë¡œ ë³€í™˜í•˜ê³  ì°¨ì› ì¶”ê°€\n",
    "    audio_tensor = torch.tensor(wav_audio, dtype=torch.float32).unsqueeze(0)\n",
    "    print(f\"WAV íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì–´ í…ì„œë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "except Exception as e:\n",
    "    print(f\"WAV íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\ë¹…ë°ì´í„°9ê¸°_ìˆ˜ì—…ìë£Œ_ì´ìˆ˜ì§€\\2024.11.04_(ì¤‘ê°„í”„ë¡œì íŠ¸)\\tortoise-tts\\tortoise\\models\\arch_util.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.mel_norms = torch.load(self.mel_norm_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í™”ì ì„ë² ë”©ì´ 'saved_embeddings/conditioning_latents_GalacticPatrol2'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# Tortoise TTSì—ì„œ í™”ì í”„ë¡œí•„ ì„ë² ë”© ìƒì„±\n",
    "conditioning_latents = tts.get_conditioning_latents([audio_tensor])\n",
    "\n",
    "# ì„ë² ë”© ì €ì¥\n",
    "embedding_path = \"saved_embeddings/conditioning_latents_GalacticPatrol2\"\n",
    "os.makedirs(os.path.dirname(embedding_path), exist_ok=True)\n",
    "np.savez(embedding_path, *conditioning_latents)\n",
    "print(f\"í™”ì ì„ë² ë”©ì´ '{embedding_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
